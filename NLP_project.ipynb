{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install textdistance"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T17:27:09.073814Z",
          "iopub.execute_input": "2023-05-31T17:27:09.074240Z",
          "iopub.status.idle": "2023-05-31T17:27:25.644344Z",
          "shell.execute_reply.started": "2023-05-31T17:27:09.074209Z",
          "shell.execute_reply": "2023-05-31T17:27:25.642968Z"
        },
        "trusted": true,
        "id": "dJXdkcUPjEZw",
        "outputId": "063f7158-d110-4b04-9ee8-5e6e5cfd5e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting textdistance\n  Downloading textdistance-4.5.0-py3-none-any.whl (31 kB)\nInstalling collected packages: textdistance\nSuccessfully installed textdistance-4.5.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Natural Language Processing Project**\n",
        "Raghad Bahashwan\n",
        "\n",
        "Wesal Alkhateeb\n",
        "\n",
        "Nojood Alnahdi\n",
        "\n",
        "Reema Talal"
      ],
      "metadata": {
        "id": "cjGaMVPXjEZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**"
      ],
      "metadata": {
        "id": "DdK2m4u6jEZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from itertools import product\n",
        "from textdistance import DamerauLevenshtein\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T17:50:54.464432Z",
          "iopub.execute_input": "2023-05-31T17:50:54.464911Z",
          "iopub.status.idle": "2023-05-31T17:50:54.482025Z",
          "shell.execute_reply.started": "2023-05-31T17:50:54.464872Z",
          "shell.execute_reply": "2023-05-31T17:50:54.479408Z"
        },
        "trusted": true,
        "id": "FmXa78ZrjEZ0",
        "outputId": "4b60c951-a573-46df-c1b4-6f1a7ee6909c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing the Dataset**\n",
        "Involves loading and cleaning a dataset of Arabic text. The text is preprocessed by removing punctuation and converting it to lowercase, which ensures consistency and prepares the data for further analysis. The preprocessed text is then saved to a CSV file for easy access."
      ],
      "metadata": {
        "id": "906aAwKmjEZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to a pandas DataFrame and save it to a CSV file\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    return text\n",
        "dir_path = '/kaggle/input/sanad-dataset/Culture'\n",
        "\n",
        "all_text = ''\n",
        "\n",
        "for filename in os.listdir(dir_path):\n",
        "    if filename.endswith('.txt'):\n",
        "        with open(os.path.join(dir_path, filename), 'r', encoding='utf-8') as f:\n",
        "            text = f.read()\n",
        "            all_text += text\n",
        "\n",
        "cleaned_text = preprocess(all_text)\n",
        "\n",
        "df = pd.DataFrame({'text': [cleaned_text]})\n",
        "df.to_csv('preprocessed_text.csv', index=False)\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T17:27:25.671338Z",
          "iopub.execute_input": "2023-05-31T17:27:25.671972Z",
          "iopub.status.idle": "2023-05-31T17:28:22.156588Z",
          "shell.execute_reply.started": "2023-05-31T17:27:25.671924Z",
          "shell.execute_reply": "2023-05-31T17:28:22.155349Z"
        },
        "trusted": true,
        "id": "yQksBwkQjEZ1",
        "outputId": "5281ebc8-07a7-4dff-d5d9-f5b2d82d98da"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                text\n0  أبوظبي آلاء عبد الغني تناولت الجلسة الثانية في...",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>أبوظبي آلاء عبد الغني تناولت الجلسة الثانية في...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Spell Checking and Suggestions**\n",
        "\n",
        "1. **Building the Dictionary and Tokenization:**\n",
        "   - A frequency dictionary is generated from the preprocessed dataset, which contains all unique words along with their frequency of occurrence. Before counting, the input sentence is tokenized into individual words using a tokenizer that handles Arabic text. This combined process ensures that the dictionary accurately represents the frequency of each word, facilitating the ranking of potential corrections for misspelled words.\n",
        "\n",
        "\n",
        "2. **Error Detection and Correction:**\n",
        "\n",
        " - For each word in the input sentence, the Damerau-Levenshtein distance algorithm is applied to detect potential spelling errors. This algorithm computes the minimum number of single-character edits (insertions, deletions, substitutions, or transpositions) needed to change the misspelled word into a valid word from the dictionary."
      ],
      "metadata": {
        "id": "K_jB7u9ojEZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the dataset\n",
        "def load_dataset(file_path):\n",
        "    df = pd.read_csv(file_path, encoding='utf-8')\n",
        "    return df\n",
        "\n",
        "# Create a dictionary from the dataset ( word frequency )\n",
        "def create_dictionary(dataframe):\n",
        "    words = []\n",
        "    for index, row in dataframe.iterrows():\n",
        "        words.extend(word_tokenize(row[0]))\n",
        "    word_counts = Counter(words)\n",
        "    return word_counts\n",
        "\n",
        "# Calculate Damerau-Levenshtein distance ( distance, operations)\n",
        "def dl_distance(word1, word2):\n",
        "    dl = DamerauLevenshtein()\n",
        "    return dl.distance(word1, word2)\n",
        "\n",
        "# Find the closest words in the dictionary to the misspelled word\n",
        "def find_closest_words(misspelled_word, dictionary, max_distance):\n",
        "    closest_words = []\n",
        "    for word, count in dictionary.items():\n",
        "        distance = dl_distance(misspelled_word, word)\n",
        "        if distance <= max_distance:\n",
        "            closest_words.append((word, count, distance))\n",
        "    closest_words.sort(key=lambda x: (x[2], -x[1]))\n",
        "    return closest_words\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T18:19:27.488474Z",
          "iopub.execute_input": "2023-05-31T18:19:27.489034Z",
          "iopub.status.idle": "2023-05-31T18:19:49.711869Z",
          "shell.execute_reply.started": "2023-05-31T18:19:27.488990Z",
          "shell.execute_reply": "2023-05-31T18:19:49.710676Z"
        },
        "trusted": true,
        "id": "dhUzp4dTjEZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. **Suggestion Generation and Providing Correction Suggestions:**\n",
        "\n",
        "After detecting potential misspellings, the system generates correction suggestions for each misspelled word. The suggestions are ranked based on:\n",
        "\n",
        "Distance: The similarity between the misspelled word and the suggested word, measured by the number of character edits.\n",
        "\n",
        "Frequency: The occurrence frequency of the suggested word in the dataset, with higher priority given to more commonly used words.\n",
        "\n",
        "\n",
        "- The final output is a list of ranked suggestions for each misspelled word, which can be presented to users for selection or automatic correction."
      ],
      "metadata": {
        "id": "UFz01tPzEVWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    file_path = \"/kaggle/input/culture-nlp/preprocessed_text.csv\"\n",
        "    df = load_dataset(file_path)\n",
        "    dictionary = create_dictionary(df)\n",
        "    # Set the maximum Damerau-Levenshtein distance to consider a word as a suggestion\n",
        "    max_distance = 1"
      ],
      "metadata": {
        "id": "jSZNjYwpESiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXAMPLE 1**"
      ],
      "metadata": {
        "id": "WOtuWT1IjEZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sentence = \"السللام علبكم مرخبا اهلاا كسف الهال\"\n",
        "words = nltk.word_tokenize(sentence)\n",
        "for misspelled_word in words:\n",
        "    closest_words = find_closest_words(misspelled_word, dictionary, max_distance)\n",
        "    print(\"Suggestions for '{}':\".format(misspelled_word))\n",
        "    # Iterate over each closest word found\n",
        "    for word, count, distance in closest_words:\n",
        "        print(\"  - {}: frequency={}, distance={}\".format(word, count, distance))\n",
        "    print()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T18:20:40.627804Z",
          "iopub.execute_input": "2023-05-31T18:20:40.628270Z",
          "iopub.status.idle": "2023-05-31T18:20:50.802303Z",
          "shell.execute_reply.started": "2023-05-31T18:20:40.628232Z",
          "shell.execute_reply": "2023-05-31T18:20:50.800713Z"
        },
        "trusted": true,
        "id": "1CEIJX-fjEZ5",
        "outputId": "5f7d29ed-091d-4cfd-9da8-4a00b6af6ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Suggestions for 'السللام':\n  - السلام: frequency=174, distance=1\n  - السلالم: frequency=2, distance=1\n\nSuggestions for 'علبكم':\n  - عليكم: frequency=11, distance=1\n  - البكم: frequency=1, distance=1\n\nSuggestions for 'مرخبا':\n  - مرحبا: frequency=17, distance=1\n  - مركبا: frequency=5, distance=1\n  - مرعبا: frequency=1, distance=1\n  - مرتبا: frequency=1, distance=1\n  - مخربا: frequency=1, distance=1\n\nSuggestions for 'اهلاا':\n  - اهلا: frequency=1, distance=1\n  - اهلال: frequency=1, distance=1\n\nSuggestions for 'كسف':\n  - كيف: frequency=715, distance=1\n  - كشف: frequency=75, distance=1\n  - كسر: frequency=56, distance=1\n  - كاف: frequency=29, distance=1\n  - كسب: frequency=22, distance=1\n  - كنف: frequency=19, distance=1\n  - كلف: frequency=13, distance=1\n  - كف: frequency=10, distance=1\n  - كتف: frequency=9, distance=1\n  - نسف: frequency=4, distance=1\n\nSuggestions for 'الهال':\n  - الحال: frequency=192, distance=1\n  - المال: frequency=93, distance=1\n  - الهول: frequency=65, distance=1\n  - الهائل: frequency=61, distance=1\n  - الهلال: frequency=49, distance=1\n  - الخال: frequency=16, distance=1\n  - البال: frequency=10, distance=1\n  - الدال: frequency=9, distance=1\n  - الهالة: frequency=9, distance=1\n  - العال: frequency=4, distance=1\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXAMPLE 2**"
      ],
      "metadata": {
        "id": "vlMX0ksOjEZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"هاذا مسروع مادةة نعالجة لعات كبيعية\"\n",
        "words = nltk.word_tokenize(sentence)\n",
        "\n",
        "for misspelled_word in words:\n",
        "\n",
        "    closest_words = find_closest_words(misspelled_word, dictionary, max_distance)\n",
        "    print(\"Suggestions for '{}':\".format(misspelled_word))\n",
        "\n",
        "    # Iterate over each closest word found\n",
        "    for word, count, distance in closest_words:\n",
        "        print(\"  - {}: frequency={}, distance={}\".format(word, count, distance))\n",
        "    print()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T18:00:58.284400Z",
          "iopub.execute_input": "2023-05-31T18:00:58.284823Z",
          "iopub.status.idle": "2023-05-31T18:01:08.250066Z",
          "shell.execute_reply.started": "2023-05-31T18:00:58.284790Z",
          "shell.execute_reply": "2023-05-31T18:01:08.248462Z"
        },
        "trusted": true,
        "id": "7xS08YwrjEZ6",
        "outputId": "08334409-59c7-49cd-e0cf-17118288f4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Suggestions for 'هاذا':\n  - هذا: frequency=7787, distance=1\n  - ماذا: frequency=202, distance=1\n  - هكذا: frequency=130, distance=1\n  - اذا: frequency=21, distance=1\n  - واذا: frequency=9, distance=1\n  - هانا: frequency=5, distance=1\n  - هاما: frequency=4, distance=1\n  - هوذا: frequency=1, distance=1\n  - هازا: frequency=1, distance=1\n  - فاذا: frequency=1, distance=1\n\nSuggestions for 'مسروع':\n  - مشروع: frequency=775, distance=1\n  - مسموع: frequency=4, distance=1\n  - مروع: frequency=3, distance=1\n  - مسرور: frequency=2, distance=1\n  - مزروع: frequency=2, distance=1\n\nSuggestions for 'مادةة':\n  - مادة: frequency=202, distance=1\n  - مادية: frequency=51, distance=1\n\nSuggestions for 'نعالجة':\n  - معالجة: frequency=85, distance=1\n  - نعالج: frequency=1, distance=1\n\nSuggestions for 'لعات':\n  - لغات: frequency=175, distance=1\n  - لعام: frequency=159, distance=1\n  - لعبت: frequency=56, distance=1\n  - لذات: frequency=7, distance=1\n  - لعزت: frequency=1, distance=1\n  - عات: frequency=1, distance=1\n  - ليعات: frequency=1, distance=1\n  - لعاد: frequency=1, distance=1\n  - لعاش: frequency=1, distance=1\n\nSuggestions for 'كبيعية':\n  - طبيعية: frequency=41, distance=1\n  - ربيعية: frequency=1, distance=1\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXAMPLE 3**"
      ],
      "metadata": {
        "id": "NzocLK0LjEZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"الصصباح لدبنا مناقسة مثروع التهرج\"\n",
        "words = nltk.word_tokenize(sentence)\n",
        "\n",
        "for misspelled_word in words:\n",
        "\n",
        "    closest_words = find_closest_words(misspelled_word, dictionary, max_distance)\n",
        "    print(\"Suggestions for '{}':\".format(misspelled_word))\n",
        "\n",
        "    # Iterate over each closest word found\n",
        "    for word, count, distance in closest_words:\n",
        "        print(\"  - {}: frequency={}, distance={}\".format(word, count, distance))\n",
        "    print()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T18:06:08.257255Z",
          "iopub.execute_input": "2023-05-31T18:06:08.257748Z",
          "iopub.status.idle": "2023-05-31T18:06:16.651750Z",
          "shell.execute_reply.started": "2023-05-31T18:06:08.257715Z",
          "shell.execute_reply": "2023-05-31T18:06:16.650200Z"
        },
        "trusted": true,
        "id": "EtqPTlwljEZ7",
        "outputId": "759500f0-c94b-488a-e8d4-220286c7ed90"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Suggestions for 'الصصباح':\n  - الصباح: frequency=84, distance=1\n  - المصباح: frequency=4, distance=1\n\nSuggestions for 'لدبنا':\n  - لدينا: frequency=170, distance=1\n  - أدبنا: frequency=12, distance=1\n  - لأدبنا: frequency=3, distance=1\n  - لعبنا: frequency=1, distance=1\n\nSuggestions for 'مناقسة':\n  - مناقشة: frequency=107, distance=1\n  - منافسة: frequency=35, distance=1\n  - مناقضة: frequency=3, distance=1\n  - مناقلة: frequency=1, distance=1\n\nSuggestions for 'مثروع':\n  - مشروع: frequency=775, distance=1\n  - مروع: frequency=3, distance=1\n  - مزروع: frequency=2, distance=1\n\nSuggestions for 'التهرج':\n  - المهرج: frequency=28, distance=1\n  - التخرج: frequency=15, distance=1\n  - التدرج: frequency=6, distance=1\n  - التهريج: frequency=4, distance=1\n  - التهرب: frequency=2, distance=1\n  - التحرج: frequency=1, distance=1\n  - الهرج: frequency=1, distance=1\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXAMPLE 4**"
      ],
      "metadata": {
        "id": "jcUwYcZrjEZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"إته اثبوع يختوي علىى الكقير نن الفغاليات\"\n",
        "words = nltk.word_tokenize(sentence)\n",
        "\n",
        "for misspelled_word in words:\n",
        "\n",
        "    closest_words = find_closest_words(misspelled_word, dictionary, max_distance)\n",
        "    print(\"Suggestions for '{}':\".format(misspelled_word))\n",
        "\n",
        "    # Iterate over each closest word found\n",
        "    for word, count, distance in closest_words:\n",
        "        print(\"  - {}: frequency={}, distance={}\".format(word, count, distance))\n",
        "    print()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T18:09:26.982457Z",
          "iopub.execute_input": "2023-05-31T18:09:26.982925Z",
          "iopub.status.idle": "2023-05-31T18:09:38.624877Z",
          "shell.execute_reply.started": "2023-05-31T18:09:26.982885Z",
          "shell.execute_reply": "2023-05-31T18:09:38.623162Z"
        },
        "trusted": true,
        "id": "vD0qCGGGjEZ8",
        "outputId": "5dba2c8b-19f3-4c96-b53b-2cb0b03219f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Suggestions for 'إته':\n  - إنه: frequency=596, distance=1\n  - إله: frequency=6, distance=1\n  - إيه: frequency=5, distance=1\n  - إتش: frequency=2, distance=1\n  - إت: frequency=1, distance=1\n  - مته: frequency=1, distance=1\n  - إنته: frequency=1, distance=1\n\nSuggestions for 'اثبوع':\n  - اسبوع: frequency=4, distance=1\n\nSuggestions for 'يختوي':\n  - يحتوي: frequency=73, distance=1\n  - يختفي: frequency=11, distance=1\n  - يستوي: frequency=7, distance=1\n  - يرتوي: frequency=1, distance=1\n  - ينتوي: frequency=1, distance=1\n\nSuggestions for 'علىى':\n  - على: frequency=29764, distance=1\n\nSuggestions for 'الكقير':\n  - الكثير: frequency=1440, distance=1\n  - الكبير: frequency=1013, distance=1\n  - الفقير: frequency=30, distance=1\n\nSuggestions for 'نن':\n  - من: frequency=60152, distance=1\n  - أن: frequency=20854, distance=1\n  - عن: frequency=14172, distance=1\n  - بن: frequency=5308, distance=1\n  - إن: frequency=3619, distance=1\n  - ان: frequency=1103, distance=1\n  - فن: frequency=754, distance=1\n  - نحن: frequency=489, distance=1\n  - نص: frequency=407, distance=1\n  - لن: frequency=343, distance=1\n  - آن: frequency=177, distance=1\n  - سن: frequency=135, distance=1\n  - كن: frequency=25, distance=1\n  - هن: frequency=24, distance=1\n  - نون: frequency=23, distance=1\n  - ظن: frequency=15, distance=1\n  - رن: frequency=13, distance=1\n  - نكن: frequency=12, distance=1\n  - شن: frequency=11, distance=1\n  - ن: frequency=9, distance=1\n  - ند: frequency=6, distance=1\n  - نظن: frequency=5, distance=1\n  - ون: frequency=5, distance=1\n  - جن: frequency=5, distance=1\n  - سنن: frequency=4, distance=1\n  - نم: frequency=3, distance=1\n  - ين: frequency=2, distance=1\n  - فنن: frequency=2, distance=1\n  - زن: frequency=2, distance=1\n  - نع: frequency=2, distance=1\n  - حن: frequency=2, distance=1\n  - نت: frequency=2, distance=1\n  - قن: frequency=2, distance=1\n  - نضن: frequency=1, distance=1\n  - ننس: frequency=1, distance=1\n  - دن: frequency=1, distance=1\n  - نر: frequency=1, distance=1\n  - نو: frequency=1, distance=1\n  - قنن: frequency=1, distance=1\n\nSuggestions for 'الفغاليات':\n  - الفعاليات: frequency=703, distance=1\n\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}